{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 3004,
          "databundleVersionId": 861823,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "name": "CNN for Digit Recognition Challenge",
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GoldenPandaMRW/KaggleCompetitions/blob/main/CNN_for_Digit_Recognition_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch # framework\n",
        "import torch.nn as nn # neural net framework\n",
        "import torchvision # dataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt # data visualization\n",
        "from torchvision import transforms\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T00:52:42.577067Z",
          "iopub.execute_input": "2025-08-14T00:52:42.578895Z",
          "iopub.status.idle": "2025-08-14T00:52:42.589761Z",
          "shell.execute_reply.started": "2025-08-14T00:52:42.578863Z",
          "shell.execute_reply": "2025-08-14T00:52:42.588512Z"
        },
        "id": "BoP3Qdv4F1Sk"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": [
        "# device config\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# hyperparamters = config of the model\n",
        "input_size = 784 # images are 28x28\n",
        "hidden_size = 100\n",
        "num_classes = 10 # 0-9 digits\n",
        "batch_size = 100"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T00:52:42.591287Z",
          "iopub.execute_input": "2025-08-14T00:52:42.591604Z",
          "iopub.status.idle": "2025-08-14T00:52:42.605585Z",
          "shell.execute_reply.started": "2025-08-14T00:52:42.591579Z",
          "shell.execute_reply": "2025-08-14T00:52:42.604726Z"
        },
        "id": "-ISty8QWF1Sl"
      },
      "outputs": [],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": [
        "class DigitRecogDataset(Dataset):\n",
        "    def __init__(self,csv_file,has_labels=True,transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.has_labels = has_labels\n",
        "        self.transform = transform\n",
        "\n",
        "        if self.has_labels:\n",
        "            # The first column of train.csv has labels for data\n",
        "            self.labels = self.data.iloc[:,0].values\n",
        "            self.images = self.data.iloc[:,1:].values\n",
        "        else:\n",
        "            # The test.csv does not contain a label\n",
        "            self.images = self.data.values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        image = self.images[index].reshape(28,28).astype('float32')/255.0\n",
        "        image = torch.tensor(image).unsqueeze(0) # (1,28,28)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.has_labels:\n",
        "            label = torch.tensor(self.labels[index],dtype=torch.long)\n",
        "            return image, label\n",
        "        else:\n",
        "            return image\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Normalize((0.5,), (0.5,))  # normalize pixel values\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T00:52:42.606631Z",
          "iopub.execute_input": "2025-08-14T00:52:42.606904Z",
          "iopub.status.idle": "2025-08-14T00:52:42.622538Z",
          "shell.execute_reply.started": "2025-08-14T00:52:42.606881Z",
          "shell.execute_reply": "2025-08-14T00:52:42.621657Z"
        },
        "id": "ULwHwbsbF1Sl"
      },
      "outputs": [],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "test_ds = DigitRecogDataset(\n",
        "    csv_file=\"/content/test.csv\",\n",
        "    has_labels=False,\n",
        "    transform=transform\n",
        ")\n",
        "train_ds = DigitRecogDataset(\n",
        "    csv_file=\"/content/train.csv\",\n",
        "    has_labels=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "#split train_ds into a sperate validation set (val_ds)\n",
        "#currently set to [10%] to give more data for training\n",
        "val_frac = 0.1\n",
        "n_val = int(len(train_ds) * val_frac)\n",
        "n_train = len(train_ds) - n_val\n",
        "train_ds, val_ds = random_split(train_ds, [n_train, n_val])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_ds,batch_size=batch_size,shuffle=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T00:52:42.623394Z",
          "iopub.execute_input": "2025-08-14T00:52:42.623689Z",
          "iopub.status.idle": "2025-08-14T00:52:46.446386Z",
          "shell.execute_reply.started": "2025-08-14T00:52:42.623668Z",
          "shell.execute_reply": "2025-08-14T00:52:46.445524Z"
        },
        "id": "P9mfYP1rF1Sm"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize\n",
        "examples = iter(train_loader)\n",
        "samples, labels = next(examples) # torch objects have the samples and labels atributes\n",
        "print(samples.shape, labels.shape)\n",
        "\n",
        "# torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
        "# 100 samples, 1 channel of color, 28 width, 28 length\n",
        "# Each class label has one value\n",
        "\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.imshow(samples[i][0], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T00:52:46.448575Z",
          "iopub.execute_input": "2025-08-14T00:52:46.448902Z",
          "iopub.status.idle": "2025-08-14T00:52:47.006888Z",
          "shell.execute_reply.started": "2025-08-14T00:52:46.448873Z",
          "shell.execute_reply": "2025-08-14T00:52:47.006027Z"
        },
        "id": "5HdxhCcyF1Sm",
        "outputId": "173e9220-63c9-4c14-a9d1-16bbad9ad3f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": [
        "class MiniCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # 1st convolution\n",
        "\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            # nn.ReLU(inplace=True) overwrites input tensor with ReLU() instead\n",
        "            # of creating a new tensor and using more memory\n",
        "\n",
        "            # 2nd convolution + MaxPool\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2), # pooling causes 28x28 --> 14x14\n",
        "            nn.Dropout(0.10),\n",
        "\n",
        "            # 3rd convolution\n",
        "            nn.Conv2d(64,128,3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            #4th convolution\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2), # pooling causes 14x14 --> 7x7\n",
        "            nn.Dropout(0.10),\n",
        "        )\n",
        "\n",
        "        # Global Average Pooling\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1), # [B, 128, 1, 1]\n",
        "            nn.Flatten(), # [B, 128]\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "        # Kaiming Init (Kaiming uniform distribution):\n",
        "        # helps establish starting weights to prevent vanishing or blowup\n",
        "        # of gradients and signals in backpropagation and forward propagation\n",
        "        # respectively (prevent RNG from ruining model training)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
        "                nn.init.zeros_(m.bias)\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return(x)\n",
        "\n",
        "model = MiniCNN(num_classes=10)\n",
        ""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T00:52:47.007827Z",
          "iopub.execute_input": "2025-08-14T00:52:47.008168Z",
          "iopub.status.idle": "2025-08-14T00:52:47.025705Z",
          "shell.execute_reply.started": "2025-08-14T00:52:47.008139Z",
          "shell.execute_reply": "2025-08-14T00:52:47.024778Z"
        },
        "id": "sWDRX9fwF1Sn"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 50\n",
        "n_steps = len(train_loader)\n",
        "\n",
        "best_acc = 0.0\n",
        "best_state = None\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1) # applies softmax automatically\n",
        "optimizer = AdamW(model.parameters(), lr = learning_rate, weight_decay = 1e-4)\n",
        "model.to(device)\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=learning_rate,\n",
        "    epochs=num_epochs,\n",
        "    steps_per_epoch=n_steps,\n",
        "    pct_start=0.2, # warmup\n",
        "    anneal_strategy='cos'\n",
        ")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        # labels enter as [B,1,28,28]\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "    # forward propagation\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels) # predicted, actual\n",
        "\n",
        "    # backward propagation\n",
        "        optimizer.zero_grad() # empty gradients\n",
        "        loss.backward() # backpropagation\n",
        "\n",
        "    # gradient cliping (prevents exploding gradients)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=1.0)\n",
        "\n",
        "    # step\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        running_loss += loss.item()*labels.size(0)\n",
        "\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            preds =  model(images).argmax(1)\n",
        "            total += labels.size(0)\n",
        "            correct += (preds == labels).sum().item()\n",
        "    val_acc = 100.0*(correct/total)\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        best_state = {k: v.cpu().clone() for k,v in model.state_dict().items()}\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | loss {running_loss/len(train_ds):.4f} | val {val_acc:.2f}%\")\n",
        "\n",
        "# load the current best model as a checkpoint\n",
        "# saves only the best model for submission\n",
        "\n",
        "if best_state:\n",
        "    model.load_state_dict(best_state)\n",
        "    model.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T00:52:47.026741Z",
          "iopub.execute_input": "2025-08-14T00:52:47.027048Z",
          "execution_failed": "2025-08-14T00:59:46.914Z"
        },
        "id": "GOyKMGfKF1So",
        "outputId": "16c2cb74-c47f-49c3-c902-c4f5fea4da04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50 | loss 1.7004 | val 85.10%\n",
            "Epoch 2/50 | loss 1.0153 | val 93.71%\n",
            "Epoch 3/50 | loss 0.7367 | val 96.86%\n",
            "Epoch 4/50 | loss 0.6567 | val 97.36%\n",
            "Epoch 5/50 | loss 0.6217 | val 96.83%\n",
            "Epoch 6/50 | loss 0.6023 | val 98.10%\n",
            "Epoch 7/50 | loss 0.5896 | val 98.74%\n",
            "Epoch 8/50 | loss 0.5799 | val 98.55%\n",
            "Epoch 9/50 | loss 0.5733 | val 98.88%\n",
            "Epoch 10/50 | loss 0.5672 | val 99.12%\n",
            "Epoch 11/50 | loss 0.5623 | val 98.93%\n",
            "Epoch 12/50 | loss 0.5579 | val 99.02%\n",
            "Epoch 13/50 | loss 0.5541 | val 98.88%\n",
            "Epoch 14/50 | loss 0.5518 | val 98.90%\n",
            "Epoch 15/50 | loss 0.5482 | val 98.95%\n",
            "Epoch 16/50 | loss 0.5463 | val 99.17%\n",
            "Epoch 17/50 | loss 0.5443 | val 99.21%\n",
            "Epoch 18/50 | loss 0.5415 | val 99.12%\n",
            "Epoch 19/50 | loss 0.5395 | val 99.29%\n",
            "Epoch 20/50 | loss 0.5384 | val 99.31%\n",
            "Epoch 21/50 | loss 0.5361 | val 99.45%\n",
            "Epoch 22/50 | loss 0.5351 | val 99.38%\n",
            "Epoch 23/50 | loss 0.5335 | val 99.36%\n",
            "Epoch 24/50 | loss 0.5324 | val 99.40%\n",
            "Epoch 25/50 | loss 0.5308 | val 99.40%\n",
            "Epoch 26/50 | loss 0.5298 | val 99.36%\n",
            "Epoch 27/50 | loss 0.5291 | val 99.48%\n",
            "Epoch 28/50 | loss 0.5276 | val 99.40%\n",
            "Epoch 29/50 | loss 0.5267 | val 99.31%\n",
            "Epoch 30/50 | loss 0.5257 | val 99.48%\n",
            "Epoch 31/50 | loss 0.5247 | val 99.40%\n",
            "Epoch 32/50 | loss 0.5241 | val 99.48%\n",
            "Epoch 33/50 | loss 0.5232 | val 99.40%\n",
            "Epoch 34/50 | loss 0.5228 | val 99.45%\n",
            "Epoch 35/50 | loss 0.5221 | val 99.50%\n",
            "Epoch 36/50 | loss 0.5215 | val 99.48%\n",
            "Epoch 37/50 | loss 0.5209 | val 99.48%\n",
            "Epoch 38/50 | loss 0.5204 | val 99.45%\n",
            "Epoch 39/50 | loss 0.5201 | val 99.40%\n",
            "Epoch 40/50 | loss 0.5196 | val 99.45%\n",
            "Epoch 41/50 | loss 0.5192 | val 99.43%\n",
            "Epoch 42/50 | loss 0.5190 | val 99.43%\n",
            "Epoch 43/50 | loss 0.5185 | val 99.45%\n",
            "Epoch 44/50 | loss 0.5184 | val 99.45%\n",
            "Epoch 45/50 | loss 0.5181 | val 99.45%\n",
            "Epoch 46/50 | loss 0.5181 | val 99.40%\n",
            "Epoch 47/50 | loss 0.5180 | val 99.50%\n",
            "Epoch 48/50 | loss 0.5179 | val 99.43%\n",
            "Epoch 49/50 | loss 0.5178 | val 99.45%\n",
            "Epoch 50/50 | loss 0.5178 | val 99.45%\n"
          ]
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        total += labels.size(0)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "print(f\"Validation accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-08-14T00:59:46.914Z"
        },
        "id": "E9BLOsvBF1So",
        "outputId": "5f49255b-c85b-4f08-9b0f-ca825d3a5fa3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 100.00%\n"
          ]
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Submission\n",
        "\n",
        "model.eval()\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for images in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ImageID\": range(1, len(predictions)+1),\n",
        "    \"Label\": predictions\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-08-14T00:59:46.915Z"
        },
        "id": "mV7NVVj7F1Sp"
      },
      "outputs": [],
      "execution_count": 10
    }
  ]
}