{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 3004,
          "databundleVersionId": 861823,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 31089,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GoldenPandaMRW/KaggleCompetitions/blob/main/CNN_for_Digit_Recognition_Challenge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch # framework\n",
        "import torch.nn as nn # neural net framework\n",
        "import torchvision # dataset\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt # data visualization\n",
        "from torchvision import transforms\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T00:52:42.577067Z",
          "iopub.execute_input": "2025-08-14T00:52:42.578895Z",
          "iopub.status.idle": "2025-08-14T00:52:42.589761Z",
          "shell.execute_reply.started": "2025-08-14T00:52:42.578863Z",
          "shell.execute_reply": "2025-08-14T00:52:42.588512Z"
        },
        "id": "BoP3Qdv4F1Sk"
      },
      "outputs": [],
      "execution_count": 14
    },
    {
      "cell_type": "code",
      "source": [
        "# device config\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# hyperparamters = config of the model\n",
        "input_size = 784 # images are 28x28\n",
        "hidden_size = 100\n",
        "num_classes = 10 # 0-9 digits\n",
        "batch_size = 100"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T00:52:42.591287Z",
          "iopub.execute_input": "2025-08-14T00:52:42.591604Z",
          "iopub.status.idle": "2025-08-14T00:52:42.605585Z",
          "shell.execute_reply.started": "2025-08-14T00:52:42.591579Z",
          "shell.execute_reply": "2025-08-14T00:52:42.604726Z"
        },
        "id": "-ISty8QWF1Sl"
      },
      "outputs": [],
      "execution_count": 15
    },
    {
      "cell_type": "code",
      "source": [
        "class DigitRecogDataset(Dataset):\n",
        "    def __init__(self,csv_file,has_labels=True,transform=None):\n",
        "        self.data = pd.read_csv(csv_file)\n",
        "        self.has_labels = has_labels\n",
        "        self.transform = transform\n",
        "\n",
        "        if self.has_labels:\n",
        "            # The first column of train.csv has labels for data\n",
        "            self.labels = self.data.iloc[:,0].values\n",
        "            self.images = self.data.iloc[:,1:].values\n",
        "        else:\n",
        "            # The test.csv does not contain a label\n",
        "            self.images = self.data.values\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        image = self.images[index].reshape(28,28).astype('float32')/255.0\n",
        "        image = torch.tensor(image).unsqueeze(0) # (1,28,28)\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        if self.has_labels:\n",
        "            label = torch.tensor(self.labels[index],dtype=torch.long)\n",
        "            return image, label\n",
        "        else:\n",
        "            return image\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Normalize((0.5,), (0.5,))  # normalize pixel values\n",
        "])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T00:52:42.606631Z",
          "iopub.execute_input": "2025-08-14T00:52:42.606904Z",
          "iopub.status.idle": "2025-08-14T00:52:42.622538Z",
          "shell.execute_reply.started": "2025-08-14T00:52:42.606881Z",
          "shell.execute_reply": "2025-08-14T00:52:42.621657Z"
        },
        "id": "ULwHwbsbF1Sl"
      },
      "outputs": [],
      "execution_count": 16
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset\n",
        "from torch.utils.data import random_split, DataLoader\n",
        "\n",
        "test_ds = DigitRecogDataset(\n",
        "    csv_file=\"/content/test.csv\",\n",
        "    has_labels=False,\n",
        "    transform=transform\n",
        ")\n",
        "train_ds = DigitRecogDataset(\n",
        "    csv_file=\"/content/train.csv\",\n",
        "    has_labels=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "#split train_ds into a sperate validation set (val_ds)\n",
        "#currently set to [10%] to give more data for training\n",
        "val_frac = 0.1\n",
        "n_val = int(len(train_ds) * val_frac)\n",
        "n_train = len(train_ds) - n_val\n",
        "train_ds, val_ds = random_split(train_ds, [n_train, n_val])\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds,   batch_size=batch_size, shuffle=False)\n",
        "test_loader = DataLoader(test_ds,batch_size=batch_size,shuffle=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T00:52:42.623394Z",
          "iopub.execute_input": "2025-08-14T00:52:42.623689Z",
          "iopub.status.idle": "2025-08-14T00:52:46.446386Z",
          "shell.execute_reply.started": "2025-08-14T00:52:42.623668Z",
          "shell.execute_reply": "2025-08-14T00:52:46.445524Z"
        },
        "id": "P9mfYP1rF1Sm"
      },
      "outputs": [],
      "execution_count": 17
    },
    {
      "cell_type": "code",
      "source": [
        "# visualize\n",
        "examples = iter(train_loader)\n",
        "samples, labels = next(examples) # torch objects have the samples and labels atributes\n",
        "print(samples.shape, labels.shape)\n",
        "\n",
        "# torch.Size([100, 1, 28, 28]) torch.Size([100])\n",
        "# 100 samples, 1 channel of color, 28 width, 28 length\n",
        "# Each class label has one value\n",
        "\n",
        "for i in range(6):\n",
        "  plt.subplot(2,3,i+1)\n",
        "  plt.imshow(samples[i][0], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T00:52:46.448575Z",
          "iopub.execute_input": "2025-08-14T00:52:46.448902Z",
          "iopub.status.idle": "2025-08-14T00:52:47.006888Z",
          "shell.execute_reply.started": "2025-08-14T00:52:46.448873Z",
          "shell.execute_reply": "2025-08-14T00:52:47.006027Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "5HdxhCcyF1Sm",
        "outputId": "0c861f1a-660f-4895-9c4b-0e43cb8be943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 6 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": [
        "class MiniCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super().__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            # 1st convolution\n",
        "\n",
        "            nn.Conv2d(1, 32, 3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(inplace=True),\n",
        "            # nn.ReLU(inplace=True) overwrites input tensor with ReLU() instead\n",
        "            # of creating a new tensor and using more memory\n",
        "\n",
        "            # 2nd convolution + MaxPool\n",
        "            nn.Conv2d(32, 64, 3, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2), # pooling causes 28x28 --> 14x14\n",
        "            nn.Dropout(0.10),\n",
        "\n",
        "            # 3rd convolution\n",
        "            nn.Conv2d(64,128,3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            #4th convolution\n",
        "            nn.Conv2d(128, 128, 3, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(2), # pooling causes 14x14 --> 7x7\n",
        "            nn.Dropout(0.10),\n",
        "        )\n",
        "\n",
        "        # Global Average Pooling\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.AdaptiveAvgPool2d(1), # [B, 128, 1, 1]\n",
        "            nn.Flatten(), # [B, 128]\n",
        "            nn.Linear(128, num_classes)\n",
        "        )\n",
        "\n",
        "        # Kaiming Init (Kaiming uniform distribution):\n",
        "        # helps establish starting weights to prevent vanishing or blowup\n",
        "        # of gradients and signals in backpropagation and forward propagation\n",
        "        # respectively (prevent RNG from ruining model training)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
        "                nn.init.zeros_(m.bias)\n",
        "            if isinstance(m, nn.Linear):\n",
        "                nn.init.kaiming_normal_(m.weight, nonlinearity=\"relu\")\n",
        "                nn.init.zeros_(m.bias)\n",
        "\n",
        "    def forward(self,x):\n",
        "        x = self.features(x)\n",
        "        x = self.classifier(x)\n",
        "        return(x)\n",
        "\n",
        "model = MiniCNN(num_classes=10)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T00:52:47.007827Z",
          "iopub.execute_input": "2025-08-14T00:52:47.008168Z",
          "iopub.status.idle": "2025-08-14T00:52:47.025705Z",
          "shell.execute_reply.started": "2025-08-14T00:52:47.008139Z",
          "shell.execute_reply": "2025-08-14T00:52:47.024778Z"
        },
        "id": "sWDRX9fwF1Sn"
      },
      "outputs": [],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Loop\n",
        "from torch.optim import AdamW\n",
        "from torch.optim.lr_scheduler import OneCycleLR\n",
        "\n",
        "learning_rate = 1e-3\n",
        "num_epochs = 30\n",
        "n_steps = len(train_loader)\n",
        "\n",
        "best_acc = 0.0\n",
        "best_state = None\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.CrossEntropyLoss(label_smoothing=0.1) # applies softmax automatically\n",
        "optimizer = AdamW(model.parameters(), lr = learning_rate, weight_decay = 1e-4)\n",
        "model.to(device)\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "scheduler = OneCycleLR(\n",
        "    optimizer,\n",
        "    max_lr=learning_rate,\n",
        "    epochs=num_epochs,\n",
        "    steps_per_epoch=n_steps,\n",
        "    pct_start=0.2, # warmup\n",
        "    anneal_strategy='cos'\n",
        ")\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        # labels enter as [B,1,28,28]\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "    # forward propagation\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels) # predicted, actual\n",
        "\n",
        "    # backward propagation\n",
        "        optimizer.zero_grad() # empty gradients\n",
        "        loss.backward() # backpropagation\n",
        "\n",
        "    # gradient cliping (prevents exploding gradients)\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(),max_norm=1.0)\n",
        "\n",
        "    # step\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        running_loss += loss.item()*labels.size(0)\n",
        "\n",
        "    model.eval()\n",
        "    correct = total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "            preds =  model(images).argmax(1)\n",
        "            total += labels.size(0)\n",
        "            correct += (preds == labels).sum().item()\n",
        "    val_acc = 100.0*(correct/total)\n",
        "\n",
        "    if val_acc > best_acc:\n",
        "        best_acc = val_acc\n",
        "        best_state = {k: v.cpu().clone() for k,v in model.state_dict().items()}\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} | loss {running_loss/len(train_ds):.4f} | val {val_acc:.2f}%\")\n",
        "\n",
        "# load the current best model as a checkpoint\n",
        "# saves only the best model for submission\n",
        "\n",
        "if best_state:\n",
        "    model.load_state_dict(best_state)\n",
        "    model.to(device)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-08-14T00:52:47.026741Z",
          "iopub.execute_input": "2025-08-14T00:52:47.027048Z",
          "execution_failed": "2025-08-14T00:59:46.914Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOyKMGfKF1So",
        "outputId": "045c548a-b576-48cd-d3e1-490c56b94d50"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30 | loss 1.6668 | val 82.10%\n",
            "Epoch 2/30 | loss 0.8732 | val 95.98%\n",
            "Epoch 3/30 | loss 0.6742 | val 97.02%\n",
            "Epoch 4/30 | loss 0.6261 | val 98.10%\n",
            "Epoch 5/30 | loss 0.6001 | val 97.26%\n",
            "Epoch 6/30 | loss 0.5859 | val 97.95%\n",
            "Epoch 7/30 | loss 0.5761 | val 98.52%\n",
            "Epoch 8/30 | loss 0.5683 | val 98.83%\n",
            "Epoch 9/30 | loss 0.5633 | val 98.02%\n",
            "Epoch 10/30 | loss 0.5579 | val 98.10%\n",
            "Epoch 11/30 | loss 0.5545 | val 98.93%\n",
            "Epoch 12/30 | loss 0.5510 | val 99.14%\n",
            "Epoch 13/30 | loss 0.5483 | val 98.98%\n",
            "Epoch 14/30 | loss 0.5464 | val 99.10%\n",
            "Epoch 15/30 | loss 0.5427 | val 99.26%\n",
            "Epoch 16/30 | loss 0.5412 | val 99.19%\n",
            "Epoch 17/30 | loss 0.5386 | val 99.14%\n",
            "Epoch 18/30 | loss 0.5364 | val 99.19%\n",
            "Epoch 19/30 | loss 0.5351 | val 99.38%\n",
            "Epoch 20/30 | loss 0.5333 | val 99.36%\n",
            "Epoch 21/30 | loss 0.5321 | val 99.29%\n",
            "Epoch 22/30 | loss 0.5309 | val 99.31%\n",
            "Epoch 23/30 | loss 0.5297 | val 99.29%\n",
            "Epoch 24/30 | loss 0.5287 | val 99.38%\n",
            "Epoch 25/30 | loss 0.5277 | val 99.24%\n",
            "Epoch 26/30 | loss 0.5270 | val 99.36%\n",
            "Epoch 27/30 | loss 0.5264 | val 99.33%\n",
            "Epoch 28/30 | loss 0.5261 | val 99.31%\n",
            "Epoch 29/30 | loss 0.5257 | val 99.33%\n",
            "Epoch 30/30 | loss 0.5255 | val 99.33%\n"
          ]
        }
      ],
      "execution_count": 20
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for batch in val_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(images)\n",
        "        preds = outputs.argmax(dim=1)\n",
        "        total += labels.size(0)\n",
        "        correct += (preds == labels).sum().item()\n",
        "\n",
        "print(f\"Validation accuracy: {100 * correct / total:.2f}%\")\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-08-14T00:59:46.914Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9BLOsvBF1So",
        "outputId": "7ccd7c22-2e1f-4a89-842d-0197fe4358e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation accuracy: 98.00%\n"
          ]
        }
      ],
      "execution_count": 21
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Submission\n",
        "\n",
        "model.eval()\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for images in test_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        predictions.extend(predicted.cpu().numpy())\n",
        "\n",
        "submission = pd.DataFrame({\n",
        "    \"ImageID\": range(1, len(predictions)+1),\n",
        "    \"Label\": predictions\n",
        "})\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2025-08-14T00:59:46.915Z"
        },
        "id": "mV7NVVj7F1Sp"
      },
      "outputs": [],
      "execution_count": 22
    }
  ]
}